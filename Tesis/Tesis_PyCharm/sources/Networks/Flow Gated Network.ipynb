{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T16:49:27.722598Z",
     "start_time": "2020-04-04T16:49:27.718011Z"
    }
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T16:49:28.151285Z",
     "start_time": "2020-04-04T16:49:28.117240Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4c7Knmsem0yC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXaDqQ6Nm0yH"
   },
   "source": [
    "### Build Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T16:51:50.962244Z",
     "start_time": "2020-04-04T16:51:50.915491Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qPLzEcGtm0yI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 01:07:35.819353: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-30 01:07:36.087549: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 01:07:37.557406: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#from keras.utils import Sequence\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Data Generator inherited from keras.utils.Sequence\n",
    "    Args: \n",
    "        directory: the path of data set, and each sub-folder will be assigned to one class\n",
    "        batch_size: the number of data points in each batch\n",
    "        shuffle: whether to shuffle the data per epoch\n",
    "    Note:\n",
    "        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, batch_size=1, shuffle=True, data_augmentation=True):\n",
    "        # Initialize the params\n",
    "        self.batch_size = batch_size\n",
    "        self.directory = directory\n",
    "        self.shuffle = shuffle\n",
    "        self.data_aug = data_augmentation\n",
    "        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n",
    "        self.X_path, self.Y_dict = self.search_data() \n",
    "        # Print basic statistics information\n",
    "        self.print_stats()\n",
    "        return None\n",
    "        \n",
    "    def search_data(self):\n",
    "        X_path = []\n",
    "        Y_dict = {}\n",
    "        # list all kinds of sub-folders\n",
    "        self.dirs = sorted(os.listdir(self.directory))\n",
    "        one_hots = np_utils.to_categorical(range(len(self.dirs)))\n",
    "        for i,folder in enumerate(self.dirs):\n",
    "            folder_path = os.path.join(self.directory,folder)\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path,file)\n",
    "                # append the each file path, and keep its label  \n",
    "                X_path.append(file_path)\n",
    "                Y_dict[file_path] = one_hots[i]\n",
    "        return X_path, Y_dict\n",
    "    \n",
    "    def print_stats(self):\n",
    "        # calculate basic information\n",
    "        self.n_files = len(self.X_path)\n",
    "        self.n_classes = len(self.dirs)\n",
    "        self.indexes = np.arange(len(self.X_path))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        # Output states\n",
    "        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
    "        for i,label in enumerate(self.dirs):\n",
    "            print('%10s : '%(label),i)\n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        # calculate the iterations of each epoch\n",
    "        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
    "        return int(steps_per_epoch)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get the data of each batch\n",
    "        \"\"\"\n",
    "        # get the indexs of each batch\n",
    "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # using batch_indexs to get path of current batch\n",
    "        batch_path = [self.X_path[k] for k in batch_indexs]\n",
    "        # get batch data\n",
    "        batch_x, batch_y = self.data_generation(batch_path)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # shuffle the data at each end of epoch\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def data_generation(self, batch_path):\n",
    "        # load data into memory, you can change the np.load to any method you want\n",
    "        batch_x = [self.load_data(x) for x in batch_path]\n",
    "        batch_y = [self.Y_dict[x] for x in batch_path]\n",
    "        # transfer the data format and take one-hot coding for labels\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        return batch_x, batch_y\n",
    "      \n",
    "    def normalize(self, data):\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        return (data-mean) / std\n",
    "    \n",
    "    def random_flip(self, video, prob):\n",
    "        s = np.random.rand()\n",
    "        if s < prob:\n",
    "            video = np.flip(m=video, axis=2)\n",
    "        return video    \n",
    "    \n",
    "    def uniform_sampling(self, video, target_frames=64):\n",
    "        # get total frames of input video and calculate sampling interval \n",
    "        len_frames = int(len(video))\n",
    "        interval = int(np.ceil(len_frames/target_frames))\n",
    "        # init empty list for sampled video and \n",
    "        sampled_video = []\n",
    "        for i in range(0,len_frames,interval):\n",
    "            sampled_video.append(video[i])     \n",
    "        # calculate numer of padded frames and fix it \n",
    "        num_pad = target_frames - len(sampled_video)\n",
    "        padding = []\n",
    "        if num_pad>0:\n",
    "            for i in range(-num_pad,0):\n",
    "                try: \n",
    "                    padding.append(video[i])\n",
    "                except:\n",
    "                    padding.append(video[0])\n",
    "            sampled_video += padding     \n",
    "        # get sampled video\n",
    "        return np.array(sampled_video, dtype=np.float32)\n",
    "    \n",
    "    def random_clip(self, video, target_frames=64):\n",
    "        start_point = np.random.randint(len(video)-target_frames)\n",
    "        return video[start_point:start_point+target_frames]\n",
    "    \n",
    "    def dynamic_crop(self, video):\n",
    "        # extract layer of optical flow from video\n",
    "        opt_flows = video[...,3]\n",
    "        # sum of optical flow magnitude of individual frame\n",
    "        magnitude = np.sum(opt_flows, axis=0)\n",
    "        # filter slight noise by threshold \n",
    "        thresh = np.mean(magnitude)\n",
    "        magnitude[magnitude<thresh] = 0\n",
    "        # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n",
    "        x_pdf = np.sum(magnitude, axis=1) + 0.001\n",
    "        y_pdf = np.sum(magnitude, axis=0) + 0.001\n",
    "        # normalize PDF of x and y so that the sum of probs = 1\n",
    "        x_pdf /= np.sum(x_pdf)\n",
    "        y_pdf /= np.sum(y_pdf)\n",
    "        # randomly choose some candidates for x and y \n",
    "        x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n",
    "        y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n",
    "        # get the mean of x and y coordinates for better robustness\n",
    "        x = int(np.mean(x_points))\n",
    "        y = int(np.mean(y_points))\n",
    "        # avoid to beyond boundaries of array\n",
    "        x = max(56,min(x,167))\n",
    "        y = max(56,min(y,167))\n",
    "        # get cropped video \n",
    "        return video[:,x-56:x+56,y-56:y+56,:]  \n",
    "    \n",
    "    def color_jitter(self,video):\n",
    "        # range of s-component: 0-1\n",
    "        # range of v component: 0-255\n",
    "        s_jitter = np.random.uniform(-0.2,0.2)\n",
    "        v_jitter = np.random.uniform(-30,30)\n",
    "        for i in range(len(video)):\n",
    "            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n",
    "            s = hsv[...,1] + s_jitter\n",
    "            v = hsv[...,2] + v_jitter\n",
    "            s[s<0] = 0\n",
    "            s[s>1] = 1\n",
    "            v[v<0] = 0\n",
    "            v[v>255] = 255\n",
    "            hsv[...,1] = s\n",
    "            hsv[...,2] = v\n",
    "            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        return video\n",
    "        \n",
    "    def load_data(self, path):\n",
    "        # load the processed .npy files which have 5 channels (1-3 for RGB, 4-5 for optical flows)\n",
    "        data = np.load(path, mmap_mode='r')\n",
    "        data = np.float32(data)\n",
    "        # sampling 64 frames uniformly from the entire video\n",
    "        data = self.uniform_sampling(video=data, target_frames=64)\n",
    "        # whether to utilize the data augmentation\n",
    "        if  self.data_aug:\n",
    "            data[...,:3] = self.color_jitter(data[...,:3])\n",
    "            data = self.random_flip(data, prob=0.5)\n",
    "        # normalize rgb images and optical flows, respectively\n",
    "        data[...,:3] = self.normalize(data[...,:3])\n",
    "        data[...,3:] = self.normalize(data[...,3:])\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tiRBuTO8m0yY"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T16:51:51.550714Z",
     "start_time": "2020-04-04T16:51:51.544436Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "FfP2e_X-m0ya"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model#,Input\n",
    "from keras.layers import Input ##############################3\n",
    "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Add, Multiply\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.core import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T16:51:51.698326Z",
     "start_time": "2020-04-04T16:51:51.694124Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract the rgb images \n",
    "def get_rgb(input_x):\n",
    "    rgb = input_x[...,:3]\n",
    "    return rgb\n",
    "\n",
    "# extract the optical flows\n",
    "def get_opt(input_x):\n",
    "    opt= input_x[...,3:5]\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T16:51:52.349970Z",
     "start_time": "2020-04-04T16:51:51.857125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 01:07:40.246942: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 01:07:40.533498: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 01:07:40.533706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 01:07:40.540741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 01:07:40.540835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 01:07:40.540870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 01:07:47.836105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 01:07:47.836238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 01:07:47.836248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-30 01:07:47.836303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-30 01:07:47.836426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1549 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 224, 22  0           []                               \n",
      "                                4, 5)]                                                            \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 64, 224, 224  0           ['input_1[0][0]']                \n",
      "                                , 3)                                                              \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 64, 224, 224  0           ['input_1[0][0]']                \n",
      "                                , 2)                                                              \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 64, 224, 224  448         ['lambda[0][0]']                 \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)              (None, 64, 224, 224  304         ['lambda_1[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 64, 224, 224  784         ['conv3d[0][0]']                 \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)              (None, 64, 224, 224  784         ['conv3d_8[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3D)   (None, 64, 112, 112  0           ['conv3d_1[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d_4 (MaxPooling3D)  (None, 64, 112, 112  0          ['conv3d_9[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 64, 112, 112  2320        ['max_pooling3d[0][0]']          \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)             (None, 64, 112, 112  2320        ['max_pooling3d_4[0][0]']        \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 64, 112, 112  784         ['conv3d_2[0][0]']               \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)             (None, 64, 112, 112  784         ['conv3d_10[0][0]']              \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPooling3D)  (None, 64, 56, 56,   0          ['conv3d_3[0][0]']               \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_5 (MaxPooling3D)  (None, 64, 56, 56,   0          ['conv3d_11[0][0]']              \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 64, 56, 56,   4640        ['max_pooling3d_1[0][0]']        \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)             (None, 64, 56, 56,   4640        ['max_pooling3d_5[0][0]']        \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 64, 56, 56,   3104        ['conv3d_4[0][0]']               \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)             (None, 64, 56, 56,   3104        ['conv3d_12[0][0]']              \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPooling3D)  (None, 64, 28, 28,   0          ['conv3d_5[0][0]']               \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_6 (MaxPooling3D)  (None, 64, 28, 28,   0          ['conv3d_13[0][0]']              \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)              (None, 64, 28, 28,   9248        ['max_pooling3d_2[0][0]']        \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)             (None, 64, 28, 28,   9248        ['max_pooling3d_6[0][0]']        \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)              (None, 64, 28, 28,   3104        ['conv3d_6[0][0]']               \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv3d_15 (Conv3D)             (None, 64, 28, 28,   3104        ['conv3d_14[0][0]']              \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_3 (MaxPooling3D)  (None, 64, 14, 14,   0          ['conv3d_7[0][0]']               \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_7 (MaxPooling3D)  (None, 64, 14, 14,   0          ['conv3d_15[0][0]']              \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 64, 14, 14,   0           ['max_pooling3d_3[0][0]',        \n",
      "                                32)                               'max_pooling3d_7[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling3d_8 (MaxPooling3D)  (None, 8, 14, 14, 3  0          ['multiply[0][0]']               \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv3d_16 (Conv3D)             (None, 8, 14, 14, 6  18496       ['max_pooling3d_8[0][0]']        \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_17 (Conv3D)             (None, 8, 14, 14, 6  12352       ['conv3d_16[0][0]']              \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " max_pooling3d_9 (MaxPooling3D)  (None, 4, 7, 7, 64)  0          ['conv3d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv3d_18 (Conv3D)             (None, 4, 7, 7, 64)  36928       ['max_pooling3d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv3d_19 (Conv3D)             (None, 4, 7, 7, 64)  12352       ['conv3d_18[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling3d_10 (MaxPooling3D  (None, 2, 3, 3, 64)  0          ['conv3d_19[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3d_20 (Conv3D)             (None, 2, 3, 3, 128  73856       ['max_pooling3d_10[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3d_21 (Conv3D)             (None, 2, 3, 3, 128  49280       ['conv3d_20[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling3d_11 (MaxPooling3D  (None, 1, 1, 1, 128  0          ['conv3d_21[0][0]']              \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['max_pooling3d_11[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          16512       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           4128        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            66          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 272,690\n",
      "Trainable params: 272,690\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(64,224,224,5))\n",
    "\n",
    "rgb = Lambda(get_rgb,output_shape=None)(inputs)\n",
    "opt = Lambda(get_opt,output_shape=None)(inputs)\n",
    "\n",
    "##################################################### RGB channel\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "##################################################### Optical Flow channel\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "\n",
    "##################################################### Fusion and Pooling\n",
    "x = Multiply()([rgb,opt])\n",
    "x = MaxPooling3D(pool_size=(8,1,1))(x)\n",
    "\n",
    "##################################################### Merging Block\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "x = Conv3D(\n",
    "    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,3,3))(x)\n",
    "\n",
    "##################################################### FC Layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Build the model\n",
    "pred = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=pred)\n",
    "model.summary()\n",
    "\n",
    "## Red neuronal de dos capas densas (fully connected) con una capa de salida Softmax.\n",
    "## La entrada (inputs) se define previamente y se alimenta a través de una capa oculta (hidden layer) x. \n",
    "## El resumen del modelo se puede obtener mediante el método summary() de la clase Model de Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the GPUs and make it parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Create a MirroredStrategy object to handle parallelism\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "with strategy.scope():\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    # Create a new model inside the scope of the strategy\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=10, validation_data=validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T16:51:53.142596Z",
     "start_time": "2020-04-04T16:51:52.367945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m     parallel_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#parallel_model.compile(optimizer=..., loss=..., metrics=[...])\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m     \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m parallel_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mmode\u001b[49m, gpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m## Codigo Original\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03mos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03mfrom keras.utils import multi_gpu_model   \u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mparallel_model = multi_gpu_model(model, gpus=4)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mode' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set the list of visible devices\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "\n",
    "# Define the strategy\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])#, \"/gpu:1\", \"/gpu:2\", \"/gpu:3\"])\n",
    "\n",
    "# Define the distributed model\n",
    "with strategy.scope():\n",
    "    #parallel_model = tf.keras.utils.clone_model(model) #Original\n",
    "    #parallel_model = tf.keras.utils.clone_model(model) #1era opción\n",
    "        \n",
    "    parallel_model = tf.keras.models.clone_model(model) #2nda opción\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    parallel_model.compile(optimizer=optimizer, loss=..., metrics=[...])\n",
    "    #parallel_model.compile(optimizer=..., loss=..., metrics=[...])\n",
    "\n",
    "    \n",
    "# Train the model\n",
    "parallel_model.fit(mode, gpus=1)\n",
    "'''\n",
    "## Codigo Original\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "from keras.utils import multi_gpu_model   \n",
    "parallel_model = multi_gpu_model(model, gpus=4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBWQTN6Mm0ym"
   },
   "source": [
    "### Model Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:28:09.335822Z",
     "start_time": "2020-04-04T17:28:09.245309Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "EGID3emEm0yn"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "parallel_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TZgW6QR8oqH"
   },
   "source": [
    "### Set Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:28:09.882036Z",
     "start_time": "2020-04-04T17:28:09.873755Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(parallel_model.optimizer.lr)\n",
    "        K.set_value(parallel_model.optimizer.lr, lr * 0.7)\n",
    "    return K.get_value(parallel_model.optimizer.lr)\n",
    "\n",
    "reduce_lr = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T06:06:34.689926Z",
     "start_time": "2020-04-02T06:06:34.684821Z"
    }
   },
   "source": [
    "- Saving the best model and training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:28:10.155451Z",
     "start_time": "2020-04-04T17:28:10.146371Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "import keras\n",
    "\n",
    "class MyCbk(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, model):\n",
    "         self.model_to_save = model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model_to_save.save('Logs/model_at_epoch_%d.h5' % (epoch+1))\n",
    "\n",
    "check_point = MyCbk(model)\n",
    "\n",
    "\n",
    "filename = 'Logs/ours_log.csv'\n",
    "csv_logger = CSVLogger(filename, separator=',', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:28:10.261900Z",
     "start_time": "2020-04-04T17:28:10.258067Z"
    }
   },
   "outputs": [],
   "source": [
    "callbacks_list = [check_point, csv_logger, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DG5y04tym0yr"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set essential params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:28:10.798973Z",
     "start_time": "2020-04-04T17:28:10.794885Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs  = 30\n",
    "num_workers = 16\n",
    "batch_size  = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- init data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:28:11.079793Z",
     "start_time": "2020-04-04T17:28:11.069620Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'ViolentFlow-opt'\n",
    "\n",
    "#train_generator = DataGenerator(directory='../Dataset/Images/train'.format(dataset), batch_size=batch_size, data_augmentation=True)\n",
    "#val_generator = DataGenerator(directory='../Dataset/Images/val'.format(dataset), batch_size=batch_size, data_augmentation=False)\n",
    "\n",
    "train_generator = DataGenerator(directory='../Dataset/Numpy_Images/train'.format(dataset), batch_size=batch_size, data_augmentation=True)\n",
    "val_generator = DataGenerator(directory='../Dataset/Numpy_Images/val'.format(dataset), batch_size=batch_size, data_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- start to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T17:36:13.080206Z",
     "start_time": "2020-04-04T17:28:11.628484Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40622,
     "status": "error",
     "timestamp": 1561260510157,
     "user": {
      "displayName": "XXXXg CXXXX",
      "photoUrl": "",
      "userId": "04701665026083715772"
     },
     "user_tz": -480
    },
    "id": "wTd5cDHBm0yt",
    "outputId": "099af51f-6278-4284-db46-6ade4b7a9fda"
   },
   "outputs": [],
   "source": [
    "hist = parallel_model.fit_generator(\n",
    "    generator=train_generator, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1, \n",
    "    epochs=num_epochs,\n",
    "    workers=num_workers ,\n",
    "    max_queue_size=4,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C3D.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
